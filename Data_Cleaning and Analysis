{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Making Dislocation Density Data Uniform"],"metadata":{"id":"dnSE2Kp4nP1V"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qne0gB7Gk7k4"},"outputs":[],"source":["import pandas as pd\n","from google.colab import files\n","\n","# Upload files\n","uploaded = files.upload()\n","\n","# Load data\n","Data_claude = pd.read_csv('Generated_Data_MM226 - Claude.csv')\n","Data_chatgpt = pd.read_csv('Generated_Data_MM226 - ChatGpt.csv')\n","Data_perplexity = pd.read_csv('Generated_Data_MM226 - Perplexity.csv')\n","Data_gemini = pd.read_csv('Generated_Data_MM226 - Gemini.csv')\n","\n","# Identify the dislocation density column in each dataset\n","dislocation_column_claude = 'Dislocation Density (m^2)'\n","dislocation_column_chatgpt = 'Dislocation Density (×10¹⁴ m⁻²)'\n","dislocation_column_perplexity = 'Dislocation Density (m^2)'\n","dislocation_column_gemini = 'Dislocation Density (m^2)'\n","\n","# Convert dislocation density values to the same scientific notation as ChatGPT\n","def convert_to_chatgpt_notation(data, column):\n","    if column in data.columns:\n","        data[column] = data[column].apply(lambda x: x / 1e14 if pd.notnull(x) else x)\n","    return data\n","\n","# Convert for each dataset\n","Data_claude = convert_to_chatgpt_notation(Data_claude, dislocation_column_claude)\n","Data_perplexity = convert_to_chatgpt_notation(Data_perplexity, dislocation_column_perplexity)\n","Data_gemini = convert_to_chatgpt_notation(Data_gemini, dislocation_column_gemini)\n","\n","# Rename columns for consistency\n","Data_claude = Data_claude.rename(columns={dislocation_column_claude: dislocation_column_chatgpt})\n","Data_perplexity = Data_perplexity.rename(columns={dislocation_column_perplexity: dislocation_column_chatgpt})\n","Data_gemini = Data_gemini.rename(columns={dislocation_column_gemini: dislocation_column_chatgpt})\n","\n","# Save the modified dataframes back to CSV files\n","Data_claude.to_csv('Data_claude.csv', index=False)\n","Data_chatgpt.to_csv('Data_chatgpt.csv', index=False)\n","Data_perplexity.to_csv('Data_perplexity.csv', index=False)\n","Data_gemini.to_csv('Data_gemini.csv', index=False)\n","\n","# Download the cleaned CSV files\n","files.download('Data_claude.csv')\n","files.download('Data_chatgpt.csv')\n","files.download('Data_perplexity.csv')\n","files.download('Data_gemini.csv')"]},{"cell_type":"markdown","source":["Download the above files and then uploaded those downloaded files in cell below"],"metadata":{"id":"IDnKnqzbbR2t"}},{"cell_type":"markdown","source":["Data Cleaning + Filling Missing Value"],"metadata":{"id":"YzmTlN6LXqFZ"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from google.colab import files\n","\n","# Upload files\n","try:\n","    uploaded = files.upload()\n","except Exception as e:\n","    print(f\"Error uploading files: {e}\")\n","    exit()\n","\n","# Get the list of uploaded files\n","file_names = list(uploaded.keys())\n","\n","# Function to clean non-numeric values in specified numeric columns\n","def clean_non_numeric(dataframe):\n","    numeric_columns = [\n","        'Test Temperature (°C)',\n","        'Grain Size (µm)',\n","        'Dislocation Density (×10¹⁴ m⁻²)',\n","        'YS (MPa)',\n","        'UTS (MPa)',\n","        'Hardness (HV)',\n","        'Elongation (%)',\n","        'Strain Rate (s⁻¹)',\n","        'n',\n","        'K (Mpa)'\n","    ]\n","\n","    for column in numeric_columns:\n","        if column in dataframe.columns:\n","            dataframe[column] = pd.to_numeric(dataframe[column], errors='coerce')\n","    return dataframe\n","\n","# Load data from each file and apply cleaning functions\n","dataframes = {}\n","for file_name in file_names:\n","    try:\n","        dataframe = pd.read_csv(file_name)\n","        dataframe = clean_non_numeric(dataframe)\n","        dataframes[file_name] = dataframe\n","    except Exception as e:\n","        print(f\"Error processing file {file_name}: {e}\")\n","\n","# Save the cleaned dataframes back to CSV files\n","for file_name, dataframe in dataframes.items():\n","    cleaned_file_name = f'{file_name}'\n","    dataframe.to_csv(cleaned_file_name, index=False)\n","\n","# Save the modified dataframes back to CSV files\n","for file_name, dataframe in dataframes.items():\n","    dataframe.to_csv(f'{file_name}', index=False)\n","\n","# Load data from each file and apply functions to fill values\n","dataframes = {}\n","for file_name in file_names:\n","    try:\n","        dataframe = pd.read_csv(file_name)\n","\n","        # Forward fill for specific columns\n","        dataframe[['Phases', 'Heat Treatment', 'Test Temperature (°C)']] = dataframe[['Phases', 'Heat Treatment', 'Test Temperature (°C)']].ffill()\n","\n","        # Fill missing values in other numeric columns with the mean of each column\n","        numeric_columns = [\n","            'Grain Size (μm)',\n","            'Dislocation Density (×10¹⁴ m⁻²)',\n","            'YS (MPa)',\n","            'UTS (MPa)',\n","            'Hardness (HV)',\n","            'Elongation (%)',\n","            'Strain Rate (s⁻¹)',\n","            'n',\n","            'K (Mpa)'\n","        ]\n","\n","        for column in numeric_columns:\n","            if column in dataframe.columns:\n","                # Convert to numeric and fill NaNs in one step\n","                dataframe[column] = pd.to_numeric(dataframe[column], errors='coerce')\n","                if dataframe[column].isnull().sum() > 0:\n","                    # Use assignment to avoid the warning\n","                    dataframe[column] = dataframe[column].fillna(dataframe[column].mean())\n","\n","        dataframes[file_name] = dataframe\n","    except Exception as e:\n","        print(f\"Error processing file {file_name}: {e}\")\n","\n","# Save the cleaned dataframes back to CSV files\n","for file_name, dataframe in dataframes.items():\n","    cleaned_file_name = f'{file_name}'\n","    dataframe.to_csv(cleaned_file_name, index=False)\n","\n","# Function to round values to 2 decimal places\n","def round_values(dataframe):\n","    for column in dataframe.columns:\n","        if dataframe[column].dtype in ['float64', 'int64']:\n","            dataframe[column] = dataframe[column].apply(lambda x: round(x, 2) if pd.notnull(x) else x)\n","    return dataframe\n","\n","# Apply rounding to each dataframe\n","for file_name, dataframe in dataframes.items():\n","    dataframes[file_name] = round_values(dataframe)\n","\n","# Save the modified dataframes back to CSV files\n","for file_name, dataframe in dataframes.items():\n","    dataframe.to_csv(f'Cleaned_{file_name}', index=False)\n","\n","# Download the cleaned CSV files\n","for file_name in file_names:\n","    cleaned_file_name = f'Cleaned_{file_name}'\n","    files.download(cleaned_file_name)\n"],"metadata":{"id":"B47KouhcqeaD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Statistics Generation"],"metadata":{"id":"iw6mIjkL4TpV"}},{"cell_type":"code","source":["import pandas as pd\n","from google.colab import files\n","\n","# Function to upload and load the cleaned data file\n","def load_data():\n","        # Upload the file\n","        uploaded = files.upload()\n","        # Get the original file name\n","        file_name = list(uploaded.keys())[0]\n","        # Load the cleaned data file\n","        data = pd.read_csv(file_name)\n","        return data\n","\n","# Load the data\n","data = load_data()\n","\n","# Select numeric fields\n","numeric_data = data.select_dtypes(include=['float64', 'int64'])\n","\n","# Calculate statistics\n","statistics = {\n","    'mean': numeric_data.mean(),\n","    'median': numeric_data.median(),\n","    'std_dev': numeric_data.std(),\n","    'min': numeric_data.min(),\n","    'max': numeric_data.max()\n","}\n","\n","# Convert statistics to a DataFrame for better readability\n","stats_df = pd.DataFrame(statistics)\n","\n","# Display the statistics\n","print(stats_df)"],"metadata":{"id":"9TvadZjZ4WHs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Plotting the data"],"metadata":{"id":"4MRC1I20TATy"}},{"cell_type":"code","source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from google.colab import files\n","\n","# Function to upload and load multiple files\n","def load_files():\n","    uploaded = files.upload()\n","    file_names = list(uploaded.keys())\n","    return file_names\n","\n","# Load the files\n","file_names = load_files()\n","\n","# Process each uploaded file\n","for file_name in file_names:\n","    try:\n","        # Load the data from the CSV file\n","        data = pd.read_csv(file_name)\n","\n","        # Select numeric columns for pair plot\n","        numeric_data = data.select_dtypes(include=['float64', 'int64'])\n","\n","        # Generate pair plot\n","        sns.pairplot(numeric_data)\n","        plt.title(f'Pair Plot for {file_name}')\n","        plt.show()\n","\n","        # Generate histogram for UTS\n","        plt.figure(figsize=(10, 5))\n","        plt.hist(data['UTS (MPa)'], bins=20, color='blue', alpha=0.7, label='UTS (MPa)')\n","        plt.xlabel('UTS (MPa)')\n","        plt.ylabel('Frequency')\n","        plt.title(f'Histogram of UTS (MPa) - {file_name}')\n","        plt.legend()\n","        plt.show()\n","\n","        # Generate histogram for YS\n","        plt.figure(figsize=(10, 5))\n","        plt.hist(data['YS (MPa)'], bins=20, color='green', alpha=0.7, label='YS (MPa)')\n","        plt.xlabel('YS (MPa)')\n","        plt.ylabel('Frequency')\n","        plt.title(f'Histogram of YS (MPa) - {file_name}')\n","        plt.legend()\n","        plt.show()\n","\n","        # Generate histogram for Hardness\n","        plt.figure(figsize=(10, 5))\n","        plt.hist(data['Hardness (HV)'], bins=20, color='purple', alpha=0.7, label='Hardness (HV)')\n","        plt.xlabel('Hardness (HV)')\n","        plt.ylabel('Frequency')\n","        plt.title(f'Histogram of Hardness (HV) - {file_name}')\n","        plt.legend()\n","        plt.show()\n","\n","        # Generate scatter plot for Grain Size vs Dislocation Density\n","        if 'Dislocation Density (×10¹⁴ m⁻²)' in data.columns:\n","            plt.figure(figsize=(10, 5))\n","            plt.scatter(data['Grain Size (μm)'], data['Dislocation Density (×10¹⁴ m⁻²)'], color='red', alpha=0.7, label='Data Points')\n","            plt.xlabel('Grain Size (μm)')\n","            plt.ylabel('Dislocation Density (×10¹⁴ m⁻²)')\n","            plt.title(f'Scatter Plot: Grain Size vs Dislocation Density - {file_name}')\n","            plt.legend()\n","            plt.grid(True)\n","            plt.show()\n","\n","        # Generate scatter plot for Grain Size vs Hardness\n","        if 'Hardness (HV)' in data.columns:\n","            plt.figure(figsize=(10, 5))\n","            plt.scatter(data['Grain Size (μm)'], data['Hardness (HV)'], color='blue', alpha=0.7, label='Data Points')\n","            plt.xlabel('Grain Size (μm)')\n","            plt.ylabel('Hardness (HV)')\n","            plt.title(f'Scatter Plot: Grain Size vs Hardness - {file_name}')\n","            plt.legend()\n","            plt.grid(True)\n","            plt.show()\n","\n","    except Exception as e:\n","        print(f\"Error processing file {file_name}: {e}\")"],"metadata":{"id":"Ko_sMuJtTCAu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Plots generated to compare with Manual Data"],"metadata":{"id":"tDUglzr5fx5f"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from google.colab import files\n","\n","# Step 1: Upload files\n","uploaded_files = files.upload()\n","\n","# Step 2: Load datasets into DataFrames\n","dfs = {}\n","for filename in uploaded_files.keys():\n","    dfs[filename] = pd.read_csv(filename)\n","\n","# Step 3: Extract relevant columns for comparison\n","properties = [\"UTS (MPa)\", \"YS (MPa)\", \"Hardness (HV)\", \"Elongation (%)\"]\n","datasets = list(dfs.keys())\n","\n","# Initialize a dictionary to store mean values of each property for each dataset\n","mean_values = {prop: [] for prop in properties}\n","\n","for dataset_name, df in dfs.items():\n","    # Ensure numeric columns are properly handled\n","    for prop in properties:\n","        if prop in df.columns:\n","            mean_values[prop].append(df[prop].mean())\n","        else:\n","            mean_values[prop].append(None)  # Handle missing columns gracefully\n","\n","# Step 4: Generate scatter plots with straight lines and markers\n","def create_scatter_line_plot(property_name, values):\n","    plt.figure(figsize=(8,6))\n","    plt.plot(datasets, values, marker='o', linestyle='-', linewidth=2)\n","    plt.title(f\"{property_name} Comparison Across Datasets\", fontsize=16)\n","    plt.xlabel(\"Datasets\", fontsize=6)\n","    plt.ylabel(property_name, fontsize=6)\n","    plt.grid(True)\n","    plt.xticks(fontsize=6)\n","    plt.yticks(fontsize=6)\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Generate plots for each property\n","for prop in properties:\n","    create_scatter_line_plot(prop, mean_values[prop])"],"metadata":{"id":"n7_6T5dbf3CM"},"execution_count":null,"outputs":[]}]}